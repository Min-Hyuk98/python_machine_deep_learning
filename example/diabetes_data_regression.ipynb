{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 연속형 데이터 --> regression 문제\n",
    "\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.data.shape, diabetes.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train, test 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 10), (111, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.25)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression by stats_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 27 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>3.36e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:05:19</td>     <th>  Log-Likelihood:    </th> <td> -1788.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   331</td>      <th>  AIC:               </th> <td>   3599.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   320</td>      <th>  BIC:               </th> <td>   3641.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  153.8711</td> <td>    3.016</td> <td>   51.019</td> <td> 0.000</td> <td>  147.937</td> <td>  159.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   24.3058</td> <td>   71.393</td> <td>    0.340</td> <td> 0.734</td> <td> -116.153</td> <td>  164.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> -247.8652</td> <td>   72.156</td> <td>   -3.435</td> <td> 0.001</td> <td> -389.826</td> <td> -105.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  469.7855</td> <td>   78.470</td> <td>    5.987</td> <td> 0.000</td> <td>  315.403</td> <td>  624.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  321.6873</td> <td>   76.396</td> <td>    4.211</td> <td> 0.000</td> <td>  171.385</td> <td>  471.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> -646.6446</td> <td>  493.861</td> <td>   -1.309</td> <td> 0.191</td> <td>-1618.270</td> <td>  324.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  351.7989</td> <td>  401.170</td> <td>    0.877</td> <td> 0.381</td> <td> -437.464</td> <td> 1141.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>  -34.4630</td> <td>  247.716</td> <td>   -0.139</td> <td> 0.889</td> <td> -521.821</td> <td>  452.894</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  117.2309</td> <td>  189.373</td> <td>    0.619</td> <td> 0.536</td> <td> -255.343</td> <td>  489.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  640.2915</td> <td>  202.076</td> <td>    3.169</td> <td> 0.002</td> <td>  242.727</td> <td> 1037.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  137.9859</td> <td>   79.022</td> <td>    1.746</td> <td> 0.082</td> <td>  -17.482</td> <td>  293.454</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.793</td> <th>  Durbin-Watson:     </th> <td>   1.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.673</td> <th>  Jarque-Bera (JB):  </th> <td>   0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.750</td> <th>  Cond. No.          </th> <td>    230.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.504\n",
       "Model:                            OLS   Adj. R-squared:                  0.489\n",
       "Method:                 Least Squares   F-statistic:                     32.55\n",
       "Date:                Sun, 27 Sep 2020   Prob (F-statistic):           3.36e-43\n",
       "Time:                        15:05:19   Log-Likelihood:                -1788.7\n",
       "No. Observations:                 331   AIC:                             3599.\n",
       "Df Residuals:                     320   BIC:                             3641.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        153.8711      3.016     51.019      0.000     147.937     159.805\n",
       "x1            24.3058     71.393      0.340      0.734    -116.153     164.764\n",
       "x2          -247.8652     72.156     -3.435      0.001    -389.826    -105.904\n",
       "x3           469.7855     78.470      5.987      0.000     315.403     624.168\n",
       "x4           321.6873     76.396      4.211      0.000     171.385     471.989\n",
       "x5          -646.6446    493.861     -1.309      0.191   -1618.270     324.980\n",
       "x6           351.7989    401.170      0.877      0.381    -437.464    1141.062\n",
       "x7           -34.4630    247.716     -0.139      0.889    -521.821     452.894\n",
       "x8           117.2309    189.373      0.619      0.536    -255.343     489.805\n",
       "x9           640.2915    202.076      3.169      0.002     242.727    1037.856\n",
       "x10          137.9859     79.022      1.746      0.082     -17.482     293.454\n",
       "==============================================================================\n",
       "Omnibus:                        0.793   Durbin-Watson:                   1.982\n",
       "Prob(Omnibus):                  0.673   Jarque-Bera (JB):                0.860\n",
       "Skew:                          -0.001   Prob(JB):                        0.651\n",
       "Kurtosis:                       2.750   Cond. No.                         230.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sm_x_train = sm.add_constant(x_train, has_constant='add')\n",
    "sm_model = sm.OLS(y_train, sm_x_train)\n",
    "fitted_sm_model = sm_model.fit()\n",
    "fitted_sm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861.22954623926"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_x_test = sm.add_constant(x_test, has_constant=\"add\")\n",
    "sm_model_predict = fitted_sm_model.predict(sm_x_test)\n",
    "\n",
    "mean_squared_error(sm_model_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LinearRegression 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24.30580715, -247.86524597,  469.78551394,  321.68732629,\n",
       "       -646.64455764,  351.79890502,  -34.46301138,  117.23086924,\n",
       "        640.29154492,  137.9858861 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5250306891271108"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861.2295462392526"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, reg.predict(x_test))\n",
    "\n",
    "# np.mean((reg.predict(x_test) - y_test)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test,reg.predict(x_test))\n",
    "plt.xlabel(\"real_value\")\n",
    "plt.ylabel(\"pred_value\")\n",
    "plt.show()\n",
    "\n",
    "## 그래도 어느정도 상관관계가 형성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회귀 계수 축소\n",
    "    - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0005)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.0005)\n",
    "lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23.96557732, -247.21055504,  470.0918811 ,  321.42116083,\n",
       "       -621.50973131,  331.85786424,  -45.06413469,  114.17015112,\n",
       "        631.05163453,  138.0257172 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524859907412629"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(x_test, y_test) ## R-square값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2862.2583404713146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, lasso.predict(x_test))\n",
    "\n",
    "## 이 때 MSE가 조금 더 낮아졌다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.05)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.05)\n",
    "ridge.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24.34105527, -222.34152298,  455.07826484,  308.44990678,\n",
       "       -121.87636168,  -67.10743713, -233.11641429,   90.37414889,\n",
       "        417.68314564,  144.931366  ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5141117185404783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2927.0057564949734"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, ridge.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0005)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic = ElasticNet(alpha=0.0005)\n",
    "elastic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  25.34714853, -208.88265005,  442.39018628,  300.98452747,\n",
       "        -94.53996418,  -83.51348942, -232.32210839,   97.19373665,\n",
       "        394.90600125,  146.69474465])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5103514761796288"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2949.657570617681"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, elastic.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21643101,  0.18696711,  0.3031625 ,  0.2717397 ,  0.34325493,\n",
       "         0.35186062, -0.28243639,  0.42883325,  0.37861731,  0.32218282],\n",
       "       [ 0.04437151, -0.38654811, -0.15628061, -0.13825564,  0.57302669,\n",
       "         0.45593985,  0.50624287, -0.06818423, -0.0261893 , -0.0849466 ],\n",
       "       [ 0.49466811, -0.10685833,  0.1675317 ,  0.51356804, -0.0685867 ,\n",
       "        -0.26969438,  0.38602787, -0.38068121,  0.0636315 ,  0.27684271],\n",
       "       [-0.4140095 , -0.67986052,  0.49982533, -0.01966734, -0.06839533,\n",
       "        -0.16777384, -0.07602005,  0.0079212 ,  0.26442742,  0.08708624]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0091252 , 0.00338394, 0.00273461, 0.00216661])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_\n",
    "\n",
    "## 진짜 성능 안좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02793062, -0.09260116,  0.02802696, -0.00393895],\n",
       "       [-0.13468605,  0.06526341,  0.00132778, -0.02235559],\n",
       "       [ 0.01294474, -0.07776417,  0.0351635 , -0.03764663],\n",
       "       ...,\n",
       "       [-0.00976257, -0.05733724,  0.02359604, -0.06437226],\n",
       "       [ 0.03295629,  0.00999424, -0.04132126,  0.07690284],\n",
       "       [-0.09056089,  0.18910814, -0.00230125, -0.01049342]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCs = pca.transform(x)\n",
    "PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(PCs, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 430.65678896, -233.89960393,  272.02621191,  589.67542799])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4595824162156593"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3305.412986773166"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, lr.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.25)\n",
    "\n",
    "reg = svm.LinearSVR()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.19342006,  0.90799532,  5.82009667,  5.16728981,  3.12121813,\n",
       "        3.24993756, -5.37470919,  5.63037892,  6.35463809,  4.65336977])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5224867434351705"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8778.581703077807"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, reg.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,reg.predict(x_test))\n",
    "plt.xlabel(\"real_value\")\n",
    "plt.ylabel(\"pred_value\")\n",
    "plt.show()\n",
    "\n",
    "# 오히려 잘 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "reg = tree.DecisionTreeRegressor()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18337166169141228"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6823.261261261261"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, reg.predict(x_test))\n",
    "\n",
    "## 성능 제일 안좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(8, 8, 8, 8))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "reg = MLPRegressor(hidden_layer_sizes=(8,8,8,8), activation='relu', solver='adam')\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5389386828843667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26171.291306653966"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, reg.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,reg.predict(x_test))\n",
    "plt.xlabel(\"real_value\")\n",
    "plt.ylabel(\"pred_value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "bagging_model = BaggingRegressor(base_estimator= LinearRegression(),\n",
    "                                 n_estimators = 10,\n",
    "                                 verbose = 1)\n",
    "fitted_bagging_model = bagging_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5424531046750624"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_bagging_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2638.192300142406"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, fitted_bagging_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bagging with for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 수:  331\n",
      "복원추출시 unique한 데이터 수: 206\n",
      "MSE: 2901.7669361725916 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 200\n",
      "MSE: 2668.9957256923835 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 201\n",
      "MSE: 2732.922636913014 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 204\n",
      "MSE: 2924.1533187128543 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 201\n",
      "MSE: 2640.034216715466 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 215\n",
      "MSE: 2607.701104458265 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 208\n",
      "MSE: 2646.3793809831527 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 223\n",
      "MSE: 2662.0744593949275 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 208\n",
      "MSE: 2713.9539342349735 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 213\n",
      "MSE: 2725.3883237136 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_predict_result = []\n",
    "print(\"x_train 수: \", x_train.shape[0])\n",
    "\n",
    "for _ in range(10):\n",
    "    data_idx = [idx for idx in range(x_train.shape[0])]\n",
    "    random_data_idx = np.random.choice(data_idx, x_train.shape[0])\n",
    "    print('복원추출시 unique한 데이터 수:', len(set(random_data_idx)))\n",
    "    x_train2 = x_train[random_data_idx]\n",
    "    y_train2 = y_train[random_data_idx]\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(x_train2, y_train2)\n",
    "    \n",
    "    pred = reg.predict(x_test)\n",
    "    \n",
    "    bagging_predict_result.append(pred)\n",
    "    print('MSE:', mean_squared_error(y_test, pred), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2632.5096492837615"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    temp_predict = []\n",
    "    for j in range(len(bagging_predict_result)):\n",
    "        temp_predict.append(bagging_predict_result[j][i])\n",
    "    bagging_predict.append(np.mean(temp_predict))\n",
    "\n",
    "mean_squared_error(y_test, bagging_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=20, max_depth=5)\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5097355873176823"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2826.8398535494002"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, reg.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ada Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=20)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "reg = AdaBoostRegressor(n_estimators=20)\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3119.118248265967"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, reg.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.459045168705702"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2858.9409087797912"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, reg.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504168237979074"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\dask\\config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_dtrain = xgb.DMatrix(data = x_train, label = y_train)\n",
    "xgb_dtest = xgb.DMatrix(data = x_test)\n",
    "\n",
    "xgb_param = {'max_depth': 10,\n",
    "             'learning_rate': 0.01,\n",
    "             'n_estimators': 15}\n",
    "\n",
    "xgb_model = xgb.train(params=xgb_param, dtrain=xgb_dtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25831.43710094354"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, xgb_model.predict(xgb_dtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 559\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 150.226586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_dtrain = lgb.Dataset(data = x_train, label = y_train)\n",
    "\n",
    "lgb_param = {'max_depth': 10,\n",
    "             'learning_rate': 0.01,\n",
    "             'n_estimators': 15}\n",
    "\n",
    "lgb_model = lgb.train(params=lgb_param, train_set=lgb_dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5005.113881064382"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, lgb_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble in Ensemble (using light gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 수:  331\n",
      "복원추출시 unique한 데이터 수: 222\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 527\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 151.673716\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5080.1789741586745 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 203\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 528\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 151.800604\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 4882.740380261404 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 213\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 522\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 145.685801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5096.6290030614255 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 207\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 498\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 150.199396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4989.447185446451 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 207\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 143.830816\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5085.453247676855 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 220\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 520\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 155.413897\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 4905.512611511334 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 211\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 521\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 152.858006\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5033.340488584687 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 212\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 525\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 142.290030\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5107.979980048941 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 207\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 520\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 143.030211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5294.374013051637 \n",
      "\n",
      "복원추출시 unique한 데이터 수: 217\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 535\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 151.592145\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 5099.514086348432 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "bagging_predict_result = []\n",
    "print(\"x_train 수: \", x_train.shape[0])\n",
    "\n",
    "for _ in range(10):\n",
    "    data_idx = [idx for idx in range(x_train.shape[0])]\n",
    "    random_data_idx = np.random.choice(data_idx, x_train.shape[0])\n",
    "    print('복원추출시 unique한 데이터 수:', len(set(random_data_idx)))\n",
    "    \n",
    "    x_train2 = x_train[random_data_idx]\n",
    "    y_train2 = y_train[random_data_idx]\n",
    "    \n",
    "    lgb_dtrain = lgb.Dataset(data = x_train2, label = y_train2)\n",
    "    lgb_param = {'max_depth': 10,\n",
    "                 'learning_rate': 0.01,\n",
    "                 'n_estimators': 15}\n",
    "    lgb_model = lgb.train(params=lgb_param, train_set=lgb_dtrain)\n",
    "\n",
    "    pred = lgb_model.predict(x_test)\n",
    "    bagging_predict_result.append(pred)\n",
    "    print('MSE:', mean_squared_error(y_test, pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5030.335947329824"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    temp_predict = []\n",
    "    for j in range(len(bagging_predict_result)):\n",
    "        temp_predict.append(bagging_predict_result[j][i])\n",
    "    bagging_predict.append(np.mean(temp_predict))\n",
    "\n",
    "mean_squared_error(y_test, bagging_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론!!\n",
    "\n",
    "- 그냥 multiple linear regression 사용할 때 성능이 가장 좋다\n",
    "- linear regression모델로 bagging 하는 것도 성능 괜찮고\n",
    "- lass, ridge, elastic_net도 안좋긴하지만 괜찮음\n",
    "- PCA, SVC, NN은 성능 매우 안좋음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
