{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jang\\\\python_machine_deep_learning\\\\7. Ensemble learning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재경로 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0   ...           1        0        0        0        0        0        0   \n",
       "1   ...           0        0        0        0        0        0        0   \n",
       "2   ...           0        0        0        0        0        0        0   \n",
       "3   ...           0        1        2        0        0        0        0   \n",
       "4   ...           1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/otto_train.csv\") # Product Category\n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 고유 아이디\\nfeat_1 ~ feat_93: 설명변수\\ntarget: 타겟변수 (1~9)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: 고유 아이디\n",
    "feat_1 ~ feat_93: 설명변수\n",
    "target: 타겟변수 (1~9)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 61878 nVar: 95\n"
     ]
    }
   ],
   "source": [
    "nCar = data.shape[0] # 데이터 개수\n",
    "nVar = data.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id'], axis = 1) # id 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 변수의 문자열을 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\"Class_1\": 1,\n",
    "                \"Class_2\": 2,\n",
    "                \"Class_3\": 3,\n",
    "                \"Class_4\": 4,\n",
    "                \"Class_5\": 5,\n",
    "                \"Class_6\": 6,\n",
    "                \"Class_7\": 7,\n",
    "                \"Class_8\": 8,\n",
    "                \"Class_9\": 9}\n",
    "after_mapping_target = data['target'].apply(lambda x: mapping_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49502, 93) (12376, 93) (49502,) (12376,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['target'])) # target을 제외한 모든 행\n",
    "X = data[feature_columns] # 설명변수\n",
    "y = after_mapping_target # 타겟변수\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할| \n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:18:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy: 76.67 %\n",
      "Time: 21.18 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboos\n",
    "import xgboost as xgb\n",
    "import time\n",
    "start = time.time() # 시작 시간 지정\n",
    "xgb_dtrain = xgb.DMatrix(data = train_x, label = train_y) # 학습 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_dtest = xgb.DMatrix(data = test_x) # 평가 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_param = {'max_depth': 10, # 트리 깊이\n",
    "             'learning_rate': 0.01, # Step Size\n",
    "             'n_estimators': 100, # Number of trees, 트리 생성 개수\n",
    "             'objective': 'multi:softmax', # 목적 함수\n",
    "             'num_class': len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "xgb_model = xgb.train(params = xgb_param, dtrain = xgb_dtrain) # 학습 진행\n",
    "xgb_model_predict = xgb_model.predict(xgb_dtest) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, xgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 3., 6., ..., 9., 2., 7.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3110\n",
      "[LightGBM] [Info] Number of data points in the train set: 49502, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -3.476745\n",
      "[LightGBM] [Info] Start training from score -1.341381\n",
      "[LightGBM] [Info] Start training from score -2.039019\n",
      "[LightGBM] [Info] Start training from score -3.135151\n",
      "[LightGBM] [Info] Start training from score -3.125444\n",
      "[LightGBM] [Info] Start training from score -1.481556\n",
      "[LightGBM] [Info] Start training from score -3.074772\n",
      "[LightGBM] [Info] Start training from score -1.986562\n",
      "[LightGBM] [Info] Start training from score -2.533374\n",
      "Accuracy: 76.28 %\n",
      "Time: 10.73 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "start = time.time() # 시작 시간 지정\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 100, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'multiclass', # 목적 함수\n",
    "            'num_class': len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01734061e-15, 2.25081693e-02, 3.62193933e-01, ...,\n",
       "        3.24234521e-02, 5.82126692e-02, 3.67722414e-02],\n",
       "       [1.14084116e-15, 5.36978636e-02, 1.90687128e-01, ...,\n",
       "        3.25081119e-01, 9.38028846e-02, 6.50463131e-02],\n",
       "       [5.94595781e-16, 9.66842220e-03, 5.82817482e-02, ...,\n",
       "        1.42318289e-02, 3.40230275e-02, 2.14919364e-02],\n",
       "       ...,\n",
       "       [7.09105769e-16, 4.63740004e-02, 1.08297559e-01, ...,\n",
       "        5.46934960e-02, 7.24513712e-02, 5.74635996e-01],\n",
       "       [9.88127136e-16, 1.54895684e-02, 5.45515599e-01, ...,\n",
       "        2.45870954e-02, 5.65410617e-02, 3.62344513e-02],\n",
       "       [7.59617500e-16, 1.49480877e-02, 7.44570300e-02, ...,\n",
       "        5.76695793e-01, 1.43227106e-01, 2.74567219e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-21fb0e1c3acf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# !pip install catboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 시작 시간 지정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcb_dtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 학습 데이터를 Catboost 모델에 맞게 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cb_param = {'max_depth': 10, # 트리 깊이\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# !pip install catboost\n",
    "import catboost as cb\n",
    "start = time.time() # 시작 시간 지정\n",
    "cb_dtrain = cb.Pool(data = train_x, label = train_y) # 학습 데이터를 Catboost 모델에 맞게 변환\n",
    "cb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 100, # Number of trees, 트리 생성 개수\n",
    "            'eval_metric': 'Accuracy', # 평가 척도\n",
    "            'loss_function': 'MultiClass'} # 손실 함수, 목적 함수\n",
    "cb_model = cb.train(pool = cb_dtrain, params = cb_param) # 학습 진행\n",
    "cb_model_predict = np.argmax(cb_model.predict(test_x), axis = 1) + 1 # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측, 인덱스의 순서를 맞추기 위해 +1\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, cb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34047199,  1.18951783,  0.4296545 , ..., -0.17528062,\n",
       "        -0.02512535, -0.23089952],\n",
       "       [-0.05653916,  0.45365426,  0.17195659, ...,  0.22287606,\n",
       "         0.26190632,  0.18447355],\n",
       "       [-0.31311   , -0.31539546, -0.31876501, ..., -0.29816626,\n",
       "        -0.238871  , -0.3180434 ],\n",
       "       ...,\n",
       "       [ 0.04726952,  0.03794315, -0.17880234, ..., -0.2456077 ,\n",
       "         0.11886516,  1.54034182],\n",
       "       [-0.55746055,  1.77202298,  0.97862619, ..., -0.33775734,\n",
       "        -0.48741853, -0.37792919],\n",
       "       [-0.31665504,  0.08335556, -0.10060578, ...,  0.67896862,\n",
       "         1.03198771, -0.14349506]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging + LightGbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\") \n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis = 1) # id, date, zipcode, lat, long  제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price'])) # Price를 제외한 모든 행\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 7:3\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 537729.263666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "start = time.time() # 시작 시간 지정\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 500, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'regression'} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210904.17249451784"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(lgb_model.predict(test_x),test_y))\n",
    "\n",
    "## bagging보다 lighgt gbm의 성능이 훨씬 좋다.. bagging부분은 밑에있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9536\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 235\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 537232.324013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jang\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9615\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 539419.070923\n",
      "9518\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 537903.508163\n",
      "9517\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 233\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 534490.075947\n",
      "9539\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 540443.381188\n",
      "9522\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 533094.333333\n",
      "9528\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 234\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 539369.139269\n",
      "9610\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 534846.547095\n",
      "9595\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 234\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 537146.479543\n",
      "9569\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 233\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 533805.739441\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "bagging_predict_result = [] # 빈 리스트 생성\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])] # 학습 데이터의 인덱스를 리스트로 변환\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) # 데이터의 1/10 크기만큼 랜덤 샘플링, // 는 소수점을 무시하기 위함\n",
    "    print(len(set(random_data_index)))\n",
    "    lgb_dtrain = lgb.Dataset(data = train_x.iloc[random_data_index,], label = train_y.iloc[random_data_index,]) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "    lgb_param = {'max_depth': 14, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 500, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'regression'} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "    lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "    predict1 = lgb_model.predict(test_x) # 테스트 데이터 예측\n",
    "    bagging_predict_result.append(predict1) # 반복문이 실행되기 전 빈 리스트에 결과 값 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([510592.6067154 , 606285.48223852, 966395.070243  , ...,\n",
       "        341284.7424465 , 913674.18468276, 459424.89772216]),\n",
       " array([ 504862.93929597,  680832.68077053, 1055304.46678369, ...,\n",
       "         320867.66075513,  999693.14688501,  456962.92751367]),\n",
       " array([ 553155.35763078,  594427.63131468, 1022246.70005527, ...,\n",
       "         354733.8255771 ,  800726.36330351,  454459.274549  ]),\n",
       " array([521463.08374441, 618324.38860237, 877375.3096109 , ...,\n",
       "        342147.75288003, 879589.72166948, 466402.79040543]),\n",
       " array([511602.04346948, 606664.23581763, 977035.95055163, ...,\n",
       "        347971.94557435, 914897.25342246, 467284.37806437]),\n",
       " array([476085.02858084, 634986.11741192, 986416.90269951, ...,\n",
       "        333835.54276121, 905609.51784528, 463156.3082503 ]),\n",
       " array([513511.01222873, 701121.19569424, 982556.53702843, ...,\n",
       "        364056.92539306, 855109.48876368, 471538.62107924]),\n",
       " array([503375.00932121, 659304.76686553, 961048.30603536, ...,\n",
       "        333203.68519486, 824833.44033243, 452953.12840656]),\n",
       " array([ 502903.7389897 ,  616842.35800646, 1040648.45366348, ...,\n",
       "         370273.34914034,  977639.54657466,  476983.3841489 ]),\n",
       " array([510794.67308111, 629029.68485703, 936471.68960295, ...,\n",
       "        329489.74481199, 953313.69946511, 459774.95544617])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging을 바탕으로 예측한 결과값에 대한 평균을 계산\n",
    "bagging_predict = [] # 빈 리스트 생성\n",
    "for lst2_index in range(test_x.shape[0]): # 테스트 데이터 개수만큼의 반복\n",
    "    temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장)\n",
    "    for lst_index in range(len(bagging_predict_result)): # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(bagging_predict_result[lst_index][lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 210425.0100548045\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과값들의 평균을 계산하여 실제 테스트 데이트의 타겟변수와 비교하여 성능 평가\n",
    "\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(bagging_predict, test_y)))) # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[510834.5493057634,\n",
       " 634781.8541578918,\n",
       " 980549.9386274231,\n",
       " 1572063.7655259552,\n",
       " 636096.5526798927,\n",
       " 365196.2133400178,\n",
       " 713653.5797769122,\n",
       " 436922.63964263594,\n",
       " 462825.86368136574,\n",
       " 492802.12823451526,\n",
       " 636571.693350724,\n",
       " 390324.7304433994,\n",
       " 299036.9024867475,\n",
       " 357766.8563606908,\n",
       " 338290.356533375,\n",
       " 1301438.8109754464,\n",
       " 364355.6522330496,\n",
       " 1035672.0144648559,\n",
       " 315233.4512617202,\n",
       " 527508.0106781425,\n",
       " 370243.2408531744,\n",
       " 1898841.9253560696,\n",
       " 674337.9012615248,\n",
       " 546793.5701628595,\n",
       " 510612.4773940481,\n",
       " 483565.2133228518,\n",
       " 295887.46994575585,\n",
       " 247239.69089305014,\n",
       " 473796.153701312,\n",
       " 541575.2645602648,\n",
       " 488380.1321851451,\n",
       " 465720.3792149758,\n",
       " 463039.6524250057,\n",
       " 552341.6074071329,\n",
       " 380141.92905168864,\n",
       " 1052412.5709579415,\n",
       " 893253.7583914523,\n",
       " 527847.2338958138,\n",
       " 353525.9925210723,\n",
       " 1556283.067412503,\n",
       " 403964.0265094987,\n",
       " 274383.1497850539,\n",
       " 506087.7853515595,\n",
       " 340264.246696503,\n",
       " 254209.21685544535,\n",
       " 238679.96916079466,\n",
       " 333680.3278954975,\n",
       " 333903.14637806965,\n",
       " 352131.07053059974,\n",
       " 567991.7738125857,\n",
       " 366559.24888872856,\n",
       " 344497.41020827263,\n",
       " 783709.2707337565,\n",
       " 336244.2470409669,\n",
       " 467482.63698619045,\n",
       " 1740132.0047329385,\n",
       " 482800.6970096764,\n",
       " 703972.9565599414,\n",
       " 330034.8576104011,\n",
       " 647632.477400466,\n",
       " 477657.4486510861,\n",
       " 375093.5905004867,\n",
       " 296459.6537033198,\n",
       " 519285.05801363726,\n",
       " 449756.5421768644,\n",
       " 282700.2103048552,\n",
       " 381677.3672033864,\n",
       " 1512599.5252839709,\n",
       " 485804.8681363213,\n",
       " 655014.6962520995,\n",
       " 435574.0609525155,\n",
       " 298843.6914963861,\n",
       " 744455.9306776169,\n",
       " 512428.46380956296,\n",
       " 510193.33432531107,\n",
       " 1277583.6796793542,\n",
       " 816648.9441744225,\n",
       " 287095.2468160491,\n",
       " 456772.01136651216,\n",
       " 944554.9961011924,\n",
       " 633178.0062033115,\n",
       " 378305.58667868684,\n",
       " 639410.4525967559,\n",
       " 359215.1641815555,\n",
       " 808308.3787113698,\n",
       " 521237.51833243266,\n",
       " 523447.2719660691,\n",
       " 557917.7524895013,\n",
       " 357687.2919533161,\n",
       " 462876.25114924926,\n",
       " 347373.9045094537,\n",
       " 394131.5051712076,\n",
       " 638540.8200530491,\n",
       " 1090470.5840913411,\n",
       " 432799.14402592275,\n",
       " 498959.92528073053,\n",
       " 359400.7460462926,\n",
       " 311431.3145010318,\n",
       " 817815.6407574709,\n",
       " 459183.01219935936,\n",
       " 257132.62411570596,\n",
       " 928037.5522964249,\n",
       " 1024585.5552071685,\n",
       " 478204.8409287239,\n",
       " 1103820.8099319425,\n",
       " 298368.41617614374,\n",
       " 490663.775799412,\n",
       " 478819.84687483835,\n",
       " 811626.3709068841,\n",
       " 2409795.441814736,\n",
       " 553082.220443214,\n",
       " 329217.2198059908,\n",
       " 562300.0642758071,\n",
       " 626584.479872016,\n",
       " 549425.1830780054,\n",
       " 337392.5126350002,\n",
       " 310562.82456605614,\n",
       " 252379.52699688217,\n",
       " 321420.87989892403,\n",
       " 338290.356533375,\n",
       " 384382.2587242214,\n",
       " 283561.054465714,\n",
       " 339454.8204044181,\n",
       " 257155.10178534733,\n",
       " 593403.6904541795,\n",
       " 656635.488765131,\n",
       " 277413.3794256611,\n",
       " 724080.7728815428,\n",
       " 454481.64760396455,\n",
       " 425747.5535942701,\n",
       " 526410.87931384,\n",
       " 467175.3016510468,\n",
       " 408552.453059751,\n",
       " 825673.7745525077,\n",
       " 375336.7547878497,\n",
       " 460616.1118493095,\n",
       " 384266.55447476474,\n",
       " 353201.6119500207,\n",
       " 895215.0028208185,\n",
       " 621738.6292968732,\n",
       " 513812.9641141868,\n",
       " 797362.056244591,\n",
       " 894265.86467485,\n",
       " 403773.8494274991,\n",
       " 258443.7296568857,\n",
       " 389616.5723625694,\n",
       " 481419.4071497157,\n",
       " 242635.98421481563,\n",
       " 417611.7537701132,\n",
       " 472085.4299574254,\n",
       " 571253.0130386611,\n",
       " 671821.7315103699,\n",
       " 546259.3690909826,\n",
       " 1141177.9603518,\n",
       " 889635.1596433489,\n",
       " 858783.7548998563,\n",
       " 594151.6202371027,\n",
       " 650690.3422667825,\n",
       " 590581.7822944658,\n",
       " 492646.8873546833,\n",
       " 644360.7120153018,\n",
       " 364607.9223339535,\n",
       " 333903.14637806965,\n",
       " 355912.3715980554,\n",
       " 366281.5324224263,\n",
       " 343012.52079496987,\n",
       " 287314.0707722778,\n",
       " 310565.38751112646,\n",
       " 451692.10683279915,\n",
       " 463488.58832631976,\n",
       " 623008.1514441734,\n",
       " 394813.31420702324,\n",
       " 465816.1030740022,\n",
       " 569412.0265970352,\n",
       " 425828.7734455825,\n",
       " 411553.4957673593,\n",
       " 353531.79759823496,\n",
       " 663012.5916444624,\n",
       " 344373.5100351819,\n",
       " 256193.56868422753,\n",
       " 311288.86259690963,\n",
       " 480010.5346887903,\n",
       " 533976.7287999911,\n",
       " 681722.4761228602,\n",
       " 471299.35388979607,\n",
       " 469615.29305282625,\n",
       " 273538.59987438633,\n",
       " 434209.23976977414,\n",
       " 349294.6321336679,\n",
       " 350412.50144359795,\n",
       " 379089.42845834617,\n",
       " 649491.8303892479,\n",
       " 1488989.9594329824,\n",
       " 1351929.3339701658,\n",
       " 265422.62913664425,\n",
       " 490091.0811575898,\n",
       " 493304.5915652005,\n",
       " 1633231.3091454008,\n",
       " 459602.9935778058,\n",
       " 462910.7654439079,\n",
       " 324545.0780105869,\n",
       " 384737.95653808024,\n",
       " 523098.4773958504,\n",
       " 760144.5181782393,\n",
       " 793810.9995873891,\n",
       " 310448.0373872292,\n",
       " 510612.4773940481,\n",
       " 304866.4429177775,\n",
       " 509072.7956362087,\n",
       " 1420119.7822570833,\n",
       " 359400.7460462926,\n",
       " 417959.21409317217,\n",
       " 456808.24318871496,\n",
       " 359400.7460462926,\n",
       " 328567.33095577906,\n",
       " 682276.3605323387,\n",
       " 793260.6992292586,\n",
       " 345488.871310935,\n",
       " 362727.9562118242,\n",
       " 359517.3238853339,\n",
       " 1684104.6437933878,\n",
       " 539641.9276738015,\n",
       " 504115.5113397424,\n",
       " 469525.1188914127,\n",
       " 525896.5808095748,\n",
       " 744553.4561350998,\n",
       " 342812.4220013571,\n",
       " 1242870.4347571249,\n",
       " 895733.3787727033,\n",
       " 462664.24097681727,\n",
       " 354219.5423593632,\n",
       " 487136.80088603386,\n",
       " 706022.6437113618,\n",
       " 298492.9519922227,\n",
       " 347640.17610389774,\n",
       " 391379.4472682244,\n",
       " 352405.14623042586,\n",
       " 358343.85981225525,\n",
       " 2463922.344334556,\n",
       " 348508.8264205649,\n",
       " 443356.2716629916,\n",
       " 462595.46713622333,\n",
       " 604990.0991006603,\n",
       " 414873.0759957698,\n",
       " 469197.7400181992,\n",
       " 307430.9718511423,\n",
       " 522660.8342434781,\n",
       " 557147.197630324,\n",
       " 722431.1212063144,\n",
       " 855398.6175005557,\n",
       " 527575.3335271185,\n",
       " 428162.927894828,\n",
       " 712057.6410916782,\n",
       " 355876.88978214277,\n",
       " 350412.50144359795,\n",
       " 523445.01973955834,\n",
       " 510799.1417296195,\n",
       " 467918.9769063243,\n",
       " 914971.7137555291,\n",
       " 367217.3915382839,\n",
       " 3161102.3018206595,\n",
       " 631551.0377425685,\n",
       " 760197.6119926922,\n",
       " 1102727.4395989904,\n",
       " 507369.8938482343,\n",
       " 677406.4586063094,\n",
       " 919958.8563522432,\n",
       " 351045.8078389505,\n",
       " 722946.3447835417,\n",
       " 429487.4727331279,\n",
       " 474484.3512310575,\n",
       " 340833.045694881,\n",
       " 286857.69786745834,\n",
       " 439796.370218855,\n",
       " 413908.0007020716,\n",
       " 1401378.5098111513,\n",
       " 303080.751411146,\n",
       " 346416.7884546197,\n",
       " 544144.7609967332,\n",
       " 366203.575267949,\n",
       " 315108.88931560714,\n",
       " 508031.8305286084,\n",
       " 365793.59032852366,\n",
       " 443707.2929712754,\n",
       " 497550.89620128495,\n",
       " 443134.3019848928,\n",
       " 367809.8921653719,\n",
       " 630543.7629088557,\n",
       " 353827.42318580893,\n",
       " 321498.39111510833,\n",
       " 797661.2275479117,\n",
       " 442878.60460661276,\n",
       " 258623.93854000588,\n",
       " 350188.77970268246,\n",
       " 649491.8303892479,\n",
       " 649198.5695042834,\n",
       " 491182.9991229102,\n",
       " 442803.7316755778,\n",
       " 455165.6432768558,\n",
       " 584365.594685478,\n",
       " 471448.15621112427,\n",
       " 540943.2951645715,\n",
       " 331175.9166597682,\n",
       " 568028.9206480574,\n",
       " 340539.00669366756,\n",
       " 802676.7996043455,\n",
       " 451692.10683279915,\n",
       " 387699.0566721608,\n",
       " 334251.5477012886,\n",
       " 333379.39275003714,\n",
       " 365021.8653086856,\n",
       " 292091.17599371215,\n",
       " 851642.9957867485,\n",
       " 1527875.5269597536,\n",
       " 975040.7126477634,\n",
       " 451263.9553258718,\n",
       " 789558.9024056229,\n",
       " 456937.46838569903,\n",
       " 803564.5815766098,\n",
       " 346381.3659519363,\n",
       " 400496.53282132687,\n",
       " 490567.28344944294,\n",
       " 265422.62913664425,\n",
       " 296732.8691326833,\n",
       " 463326.1197266878,\n",
       " 463488.58832631976,\n",
       " 592735.0328082556,\n",
       " 298694.79073988687,\n",
       " 509126.0499108907,\n",
       " 257155.10178534733,\n",
       " 665934.7054247002,\n",
       " 291508.77524132404,\n",
       " 496940.555466971,\n",
       " 300988.7165988786,\n",
       " 389863.44399149634,\n",
       " 479707.27589845133,\n",
       " 604510.2910827228,\n",
       " 473410.39576372446,\n",
       " 938714.8140253207,\n",
       " 251236.4276712338,\n",
       " 1715700.9002138353,\n",
       " 475388.5158063414,\n",
       " 442957.11586166825,\n",
       " 569438.6690242254,\n",
       " 684802.0966685652,\n",
       " 621166.2513606539,\n",
       " 341511.26138074824,\n",
       " 462426.9058469464,\n",
       " 473712.7445941333,\n",
       " 704245.5007835317,\n",
       " 282387.4917441387,\n",
       " 364019.33741254115,\n",
       " 473770.99809014983,\n",
       " 625869.54077873,\n",
       " 339173.5805329158,\n",
       " 861451.4572851753,\n",
       " 558875.8914031987,\n",
       " 926605.0344848664,\n",
       " 978356.0601982037,\n",
       " 633901.2953022362,\n",
       " 367579.6186812602,\n",
       " 805767.3483595736,\n",
       " 351993.77454379975,\n",
       " 566710.4020976897,\n",
       " 679567.8570207865,\n",
       " 328621.40564932686,\n",
       " 758860.0657162641,\n",
       " 395570.42937360145,\n",
       " 975184.8243528974,\n",
       " 385022.991783304,\n",
       " 501317.60799663083,\n",
       " 654976.8914328881,\n",
       " 577376.2794653021,\n",
       " 349154.96742971806,\n",
       " 547010.4155399789,\n",
       " 378563.06317476276,\n",
       " 336842.91618324077,\n",
       " 548607.4483947303,\n",
       " 386064.5318604318,\n",
       " 419494.8469035819,\n",
       " 368253.27228318556,\n",
       " 685574.7048577641,\n",
       " 637306.002970439,\n",
       " 427104.9349722988,\n",
       " 462126.55273027887,\n",
       " 460738.0325812228,\n",
       " 299759.7251644295,\n",
       " 489430.3817490423,\n",
       " 432462.6131194831,\n",
       " 467477.9992657887,\n",
       " 565018.7125312035,\n",
       " 390510.57571929833,\n",
       " 380431.38012188487,\n",
       " 404830.2695156982,\n",
       " 1368194.9705047684,\n",
       " 385022.991783304,\n",
       " 346381.3659519363,\n",
       " 1201633.4771135822,\n",
       " 654936.0749690735,\n",
       " 384608.5274040485,\n",
       " 435574.0609525155,\n",
       " 474808.3463837141,\n",
       " 658276.8303617587,\n",
       " 457368.94106011325,\n",
       " 391337.9686445193,\n",
       " 429186.1215928712,\n",
       " 463488.58832631976,\n",
       " 425747.5535942701,\n",
       " 485948.7358573655,\n",
       " 469660.8867388194,\n",
       " 350406.8666995069,\n",
       " 475493.8070765418,\n",
       " 613341.7146572623,\n",
       " 423738.29468437843,\n",
       " 268701.268433158,\n",
       " 383670.7623728832,\n",
       " 462957.35488071886,\n",
       " 450470.13394975977,\n",
       " 1115609.327114641,\n",
       " 455941.64695492823,\n",
       " 394075.6861847797,\n",
       " 562836.9586065792,\n",
       " 333665.49698222417,\n",
       " 658298.9200009976,\n",
       " 408901.84258234996,\n",
       " 476829.48121997743,\n",
       " 486335.7856727179,\n",
       " 475564.3187525991,\n",
       " 564147.5939939594,\n",
       " 335145.64220220025,\n",
       " 598056.3757213816,\n",
       " 509172.6097467222,\n",
       " 703201.8433386094,\n",
       " 535505.9968771555,\n",
       " 513331.68697523174,\n",
       " 499344.3478209151,\n",
       " 518807.01015985076,\n",
       " 383064.9733070579,\n",
       " 362806.7425786296,\n",
       " 352727.8080191576,\n",
       " 645467.3478233392,\n",
       " 382493.0371889605,\n",
       " 358297.90866019257,\n",
       " 275386.57858435763,\n",
       " 368453.94992493745,\n",
       " 381479.6408914714,\n",
       " 825673.7745525077,\n",
       " 2363693.4671378774,\n",
       " 449754.8962197793,\n",
       " 1175754.7130452453,\n",
       " 504716.3632696162,\n",
       " 267869.6720110548,\n",
       " 483100.3250559451,\n",
       " 451733.86836183106,\n",
       " 428741.5543007602,\n",
       " 665368.0989878617,\n",
       " 378369.0541450072,\n",
       " 839945.7408749815,\n",
       " 369418.69774484384,\n",
       " 277331.91486030386,\n",
       " 466128.60519076185,\n",
       " 632872.3919101185,\n",
       " 1014226.3193880217,\n",
       " 375179.5719893569,\n",
       " 707231.515745003,\n",
       " 453959.24091305427,\n",
       " 354132.8646957682,\n",
       " 540632.3023775186,\n",
       " 940747.8666635618,\n",
       " 434674.26334785426,\n",
       " 473410.39576372446,\n",
       " 350406.8666995069,\n",
       " 456117.5598318743,\n",
       " 1223936.2983080077,\n",
       " 445868.2969812096,\n",
       " 495631.54345421947,\n",
       " 387396.41193869326,\n",
       " 453548.6997395853,\n",
       " 315033.06669354334,\n",
       " 456028.89488726325,\n",
       " 301053.58372856607,\n",
       " 336129.4665022244,\n",
       " 343917.75174520415,\n",
       " 385781.6208820112,\n",
       " 446314.8123406271,\n",
       " 607014.3798337404,\n",
       " 521065.4088661963,\n",
       " 335745.98226447107,\n",
       " 755316.4518679238,\n",
       " 659090.0690225627,\n",
       " 703323.1974677125,\n",
       " 350570.40746283403,\n",
       " 425828.7734455825,\n",
       " 650236.4234615696,\n",
       " 1888291.2636203647,\n",
       " 500315.38633872557,\n",
       " 682897.9360884416,\n",
       " 366119.4742778834,\n",
       " 370587.57349455357,\n",
       " 345991.9947008747,\n",
       " 701304.5249142476,\n",
       " 477657.4486510861,\n",
       " 317057.2038813022,\n",
       " 528180.8104602116,\n",
       " 349570.82769311185,\n",
       " 555841.9275538159,\n",
       " 793832.5109519891,\n",
       " 1045445.2460794777,\n",
       " 327395.25033113477,\n",
       " 534365.7562336359,\n",
       " 1201320.5720439448,\n",
       " 463488.58832631976,\n",
       " 805493.7772606092,\n",
       " 623667.7060702017,\n",
       " 461207.0324660523,\n",
       " 830266.677719608,\n",
       " 720054.2685004526,\n",
       " 254283.04485574923,\n",
       " 375093.5905004867,\n",
       " 283065.20873472403,\n",
       " 426496.34546308604,\n",
       " 528835.555034641,\n",
       " 335741.9957758022,\n",
       " 486478.5421474109,\n",
       " 528215.4812384832,\n",
       " 409358.7631819824,\n",
       " 496072.62210290105,\n",
       " 355982.1829041865,\n",
       " 828121.1091247827,\n",
       " 342994.1283563593,\n",
       " 378883.25571715785,\n",
       " 370601.6818152901,\n",
       " 1195516.0161812245,\n",
       " 461964.9300257303,\n",
       " 283083.2273120683,\n",
       " 282638.96292169683,\n",
       " 466654.2967210336,\n",
       " 823041.9763438113,\n",
       " 475574.84508061904,\n",
       " 666805.0943777225,\n",
       " 540125.039225287,\n",
       " 449155.9791806402,\n",
       " 956717.9846409993,\n",
       " 281484.3836516312,\n",
       " 923911.4560397215,\n",
       " 632267.5825591508,\n",
       " 518822.87996763736,\n",
       " 1032105.0679033322,\n",
       " 469659.9621473967,\n",
       " 277888.55180857534,\n",
       " 869188.3497822318,\n",
       " 342513.53264812805,\n",
       " 628965.8699759722,\n",
       " 1419408.0603204707,\n",
       " 346385.5708288179,\n",
       " 499546.6991326901,\n",
       " 451653.8997983133,\n",
       " 362880.36090643797,\n",
       " 254248.15712412796,\n",
       " 876458.6719257392,\n",
       " 434041.71133385703,\n",
       " 281936.88082506356,\n",
       " 473154.9003345563,\n",
       " 353201.655248919,\n",
       " 283133.3303639689,\n",
       " 496541.4894583031,\n",
       " 353514.0088596818,\n",
       " 417752.83798386506,\n",
       " 391547.75854948757,\n",
       " 480463.37430510455,\n",
       " 482373.7071641985,\n",
       " 539894.4616585525,\n",
       " 789075.556828487,\n",
       " 333983.11494158756,\n",
       " 326508.86463669746,\n",
       " 382493.0371889605,\n",
       " 384737.95653808024,\n",
       " 325422.5837882234,\n",
       " 433215.589766124,\n",
       " 764311.5091804813,\n",
       " 496771.86234224244,\n",
       " 844501.9997115843,\n",
       " 835053.9048151191,\n",
       " 474916.6652724391,\n",
       " 444722.2828309719,\n",
       " 477205.3233167043,\n",
       " 314854.77412034816,\n",
       " 406065.33820257295,\n",
       " 444484.55442763853,\n",
       " 308865.1503627071,\n",
       " 472763.12935299036,\n",
       " 666805.0943777225,\n",
       " 422410.748729669,\n",
       " 412658.2548168158,\n",
       " 462577.19108944555,\n",
       " 407178.98226110614,\n",
       " 1032920.2090011267,\n",
       " 785746.2714867668,\n",
       " 737378.6975196991,\n",
       " 373111.90323283715,\n",
       " 460738.0325812228,\n",
       " 400208.04852404876,\n",
       " 564980.6308667663,\n",
       " 269685.88792938594,\n",
       " 388293.0488431973,\n",
       " 357208.57885314734,\n",
       " 313903.92384407565,\n",
       " 354586.65420964087,\n",
       " 284557.08506581804,\n",
       " 409841.7615965997,\n",
       " 596469.8672342299,\n",
       " 309985.53020804335,\n",
       " 443003.241235401,\n",
       " 513859.73710112897,\n",
       " 487486.19134788273,\n",
       " 355260.7136708807,\n",
       " 335889.8698271271,\n",
       " 283737.52207470837,\n",
       " 541168.608029722,\n",
       " 472686.86510417925,\n",
       " 1727038.082396935,\n",
       " 461207.0324660523,\n",
       " 2221501.3411178915,\n",
       " 670612.757653525,\n",
       " 1042164.4443153242,\n",
       " 618327.9115973662,\n",
       " 421639.7481832233,\n",
       " 457514.1754525993,\n",
       " 970448.7107707008,\n",
       " 683323.729536176,\n",
       " 476855.52082318906,\n",
       " 483311.6381205445,\n",
       " 757774.6226966942,\n",
       " 509997.0014408907,\n",
       " 385135.58585154125,\n",
       " 400374.74246119184,\n",
       " 362020.12901165825,\n",
       " 469845.566536938,\n",
       " 333139.38886572525,\n",
       " 745798.1746244025,\n",
       " 508226.55559643154,\n",
       " 805767.3483595736,\n",
       " 701657.862978581,\n",
       " 503380.8329449237,\n",
       " 448323.8621476246,\n",
       " 497884.8520498468,\n",
       " 490359.0155851121,\n",
       " 502905.3704298249,\n",
       " 571027.9203173697,\n",
       " 307323.6555810351,\n",
       " 1087881.2170544167,\n",
       " 308714.59121527884,\n",
       " 584839.2788460604,\n",
       " 276541.1231772092,\n",
       " 1740121.608309206,\n",
       " 827899.0608751774,\n",
       " 624135.782001359,\n",
       " 518765.94279332337,\n",
       " 649096.6748528557,\n",
       " 554951.7324132706,\n",
       " 349627.2854864541,\n",
       " 523438.38052455836,\n",
       " 464929.3479430558,\n",
       " 1000083.7649080079,\n",
       " 376960.6101818566,\n",
       " 507350.2174514821,\n",
       " 1045539.3220429311,\n",
       " 527596.8020653396,\n",
       " 454534.4935346609,\n",
       " 452534.1429957886,\n",
       " 1106380.9305570365,\n",
       " 319476.5166545259,\n",
       " 630816.4414474018,\n",
       " 794243.7814671809,\n",
       " 319476.5166545259,\n",
       " 623865.8401831657,\n",
       " 588506.6277510317,\n",
       " 401551.94496003253,\n",
       " 473769.78075461445,\n",
       " 616050.8163411329,\n",
       " 435426.5956055311,\n",
       " 350570.40746283403,\n",
       " 526901.0319012637,\n",
       " 276541.1231772092,\n",
       " 347124.9774489312,\n",
       " 473142.19984746736,\n",
       " 533976.6557652216,\n",
       " 450131.1595207451,\n",
       " 799534.6790804446,\n",
       " 409175.9373807011,\n",
       " 299036.9024867475,\n",
       " 324906.9743875676,\n",
       " 469660.8867388194,\n",
       " 715288.678522034,\n",
       " 765105.6090960414,\n",
       " 367217.3915382839,\n",
       " 296659.4180123209,\n",
       " 382288.4395741067,\n",
       " 273109.710897637,\n",
       " 858358.0317861091,\n",
       " 401047.4418429284,\n",
       " 287095.94811364694,\n",
       " 340312.04725728335,\n",
       " 488236.7747270774,\n",
       " 502088.16739324294,\n",
       " 469660.8867388194,\n",
       " 1136360.0467891342,\n",
       " 1064075.9819926708,\n",
       " 1180003.368706218,\n",
       " 438429.65350780764,\n",
       " 578134.1423874963,\n",
       " 363797.28101299226,\n",
       " 520008.5155382369,\n",
       " 356213.45349126897,\n",
       " 392049.69463703793,\n",
       " 346390.87872875284,\n",
       " 815495.6117404674,\n",
       " 467482.63698619045,\n",
       " 358963.362232668,\n",
       " 389565.9287386386,\n",
       " 288367.56900695636,\n",
       " 531558.3829113321,\n",
       " 481603.47810017335,\n",
       " 425201.0697628668,\n",
       " 524635.2463070023,\n",
       " 274405.9500573572,\n",
       " 632454.8270532113,\n",
       " 524360.5523940157,\n",
       " 456772.01136651216,\n",
       " 471448.15621112427,\n",
       " 298841.32421555195,\n",
       " 359514.6103846628,\n",
       " 1211754.218990156,\n",
       " 767761.6832068373,\n",
       " 444726.92055137374,\n",
       " 319685.2027533576,\n",
       " 348904.77311480715,\n",
       " 1004005.3696855858,\n",
       " 550626.3455006031,\n",
       " 429385.9111843941,\n",
       " 278151.47785141354,\n",
       " 383484.0576044461,\n",
       " 298786.23225723306,\n",
       " 852939.2452046782,\n",
       " 254209.21685544535,\n",
       " 322827.79276135203,\n",
       " 295887.46994575585,\n",
       " 469197.7400181992,\n",
       " 476668.91905181354,\n",
       " 592003.2574715675,\n",
       " 570830.7719135841,\n",
       " 386254.2118332031,\n",
       " 472739.20509138086,\n",
       " 562546.1974508573,\n",
       " 485733.21566555975,\n",
       " 470838.28244223667,\n",
       " 621738.6292968732,\n",
       " 509131.75995257625,\n",
       " 774695.990172223,\n",
       " 388313.0362749964,\n",
       " 317501.8777284785,\n",
       " 467107.8490186399,\n",
       " 582184.2415718713,\n",
       " 474722.092157026,\n",
       " 489808.0249787381,\n",
       " 885594.4770920103,\n",
       " 529222.8297812269,\n",
       " 720351.7140304453,\n",
       " 618363.5073234832,\n",
       " 826889.9879526553,\n",
       " 277282.6097453957,\n",
       " 477285.34250041674,\n",
       " 472582.54990214214,\n",
       " 822716.4966255315,\n",
       " 860749.1008317696,\n",
       " 271591.54578126344,\n",
       " 258443.7296568857,\n",
       " 484875.2107613556,\n",
       " 291344.9600855015,\n",
       " 694574.1619285636,\n",
       " 390055.65718792065,\n",
       " 481182.16086759773,\n",
       " 508535.3263405332,\n",
       " 386262.050542403,\n",
       " 295887.46994575585,\n",
       " 292626.11328632873,\n",
       " 323755.272875097,\n",
       " 632438.9088299585,\n",
       " 283969.17746164696,\n",
       " 375543.2419603264,\n",
       " 474034.8213074142,\n",
       " 387383.39494275826,\n",
       " 518807.01015985076,\n",
       " 376896.47713261395,\n",
       " 392049.69463703793,\n",
       " 467482.63698619045,\n",
       " 355950.1743101032,\n",
       " 1241194.203887097,\n",
       " 622924.7959498216,\n",
       " 327970.87897468556,\n",
       " 455284.2514114158,\n",
       " 764449.2492939812,\n",
       " 634404.5259848787,\n",
       " 272214.3654588315,\n",
       " 470674.3866730975,\n",
       " 389863.44399149634,\n",
       " 298499.13756836404,\n",
       " 873362.3934726315,\n",
       " 474708.7535933342,\n",
       " 554725.4058295763,\n",
       " 474592.1530002669,\n",
       " 675856.8390786395,\n",
       " 575772.2001705806,\n",
       " 874698.4396003137,\n",
       " 655014.6962520995,\n",
       " 770866.7356876973,\n",
       " 376070.4018456709,\n",
       " 966782.3615532089,\n",
       " 626784.4593621113,\n",
       " 761754.0107017632,\n",
       " 467755.172219172,\n",
       " 467118.3083362652,\n",
       " 378369.0541450072,\n",
       " 467482.63698619045,\n",
       " 375093.5905004867,\n",
       " 797362.056244591,\n",
       " 524228.8954935915,\n",
       " 492650.00050076365,\n",
       " 282577.3715686373,\n",
       " 276541.1231772092,\n",
       " 298644.9791806943,\n",
       " 810823.1564303685,\n",
       " 647632.477400466,\n",
       " 458640.25364942086,\n",
       " 357615.36037387134,\n",
       " 469670.63786301983,\n",
       " 365021.8653086856,\n",
       " 650743.884548771,\n",
       " 277409.9912832271,\n",
       " 643936.7688575198,\n",
       " 527380.2269097461,\n",
       " 349256.26665838395,\n",
       " 277402.9094814572,\n",
       " 485804.8681363213,\n",
       " 504862.5405928598,\n",
       " 374571.6181101485,\n",
       " 691490.1815478557,\n",
       " 336129.4665022244,\n",
       " 390055.65718792065,\n",
       " 541545.3967362978,\n",
       " 301613.73067679506,\n",
       " 571044.6899404961,\n",
       " 689048.4671914494,\n",
       " 698959.5485579888,\n",
       " 490048.5328272106,\n",
       " 425005.8816825972,\n",
       " 703321.0209298288,\n",
       " 508570.15577982337,\n",
       " 647632.477400466,\n",
       " 1485860.9400643336,\n",
       " 554555.0922881527,\n",
       " 340891.3733397521,\n",
       " 699625.0586989303,\n",
       " 800832.1545475782,\n",
       " 340333.1756096927,\n",
       " 410782.5455201632,\n",
       " 378305.58667868684,\n",
       " 291653.14781800605,\n",
       " 508742.0705187324,\n",
       " 496464.7921540007,\n",
       " 405498.6712198438,\n",
       " 492850.1406410184,\n",
       " 326778.7416826617,\n",
       " 374463.53822142485,\n",
       " 254264.97941471048,\n",
       " 353201.6119500207,\n",
       " 346381.3659519363,\n",
       " 331582.9018647542,\n",
       " 345837.78377611144,\n",
       " 332492.49393331807,\n",
       " 826344.0151311016,\n",
       " 421862.60762631346,\n",
       " 436076.75038958807,\n",
       " 707352.0375282146,\n",
       " 352319.8412517001,\n",
       " 254209.21685544535,\n",
       " 373374.71412379184,\n",
       " 287416.9484314565,\n",
       " 575570.8801413827,\n",
       " 301921.80394574703,\n",
       " 516269.4244942449,\n",
       " 813928.4180142187,\n",
       " 578749.9008920859,\n",
       " 562549.0357565379,\n",
       " 500455.8609103593,\n",
       " 268257.52608212916,\n",
       " 926881.4008194944,\n",
       " 636096.5526798927,\n",
       " 855398.6175005557,\n",
       " 323790.5573619864,\n",
       " 464608.54629693006,\n",
       " 797321.0950440674,\n",
       " 509863.95516575966,\n",
       " 257110.9093197089,\n",
       " 1146918.3638793163,\n",
       " 311293.15232245723,\n",
       " 631458.4227268158,\n",
       " 473154.9003345563,\n",
       " 747700.442973915,\n",
       " 548629.4262158975,\n",
       " 453959.24091305427,\n",
       " 460738.0325812228,\n",
       " 444291.16407784744,\n",
       " 549426.2829806346,\n",
       " 1305167.571342252,\n",
       " 476145.549627419,\n",
       " 844093.4839178079,\n",
       " 484508.3960669503,\n",
       " 379957.24551965983,\n",
       " 274295.24079849146,\n",
       " 433811.38332520146,\n",
       " 552141.4202334865,\n",
       " 487723.949907385,\n",
       " 454102.0030010919,\n",
       " 298786.23225723306,\n",
       " 363071.4774054661,\n",
       " 349357.42219841026,\n",
       " 510897.13968454336,\n",
       " 567064.931842039,\n",
       " 282833.55334778543,\n",
       " 382087.222052334,\n",
       " 501585.7148982592,\n",
       " 623865.8401831657,\n",
       " 1019144.5939963858,\n",
       " 656899.2945320702,\n",
       " 357603.29118415434,\n",
       " 766680.335896466,\n",
       " 700120.1365754295,\n",
       " 843877.5991215985,\n",
       " 353865.7839388046,\n",
       " 2244896.9139877916,\n",
       " 366900.5820893618,\n",
       " 379600.2027602318,\n",
       " 503136.64873503306,\n",
       " 333665.49698222417,\n",
       " 358042.8509816078,\n",
       " 546379.2474167699,\n",
       " 650969.3618928303,\n",
       " 692357.0268029784,\n",
       " 276463.04675428604,\n",
       " 349154.96742971806,\n",
       " 551978.5981918927,\n",
       " 2353033.526878693,\n",
       " 551499.1853808896,\n",
       " 468183.98625806626,\n",
       " 901826.0941902496,\n",
       " 634181.3576669332,\n",
       " 551894.0173219567,\n",
       " 774669.9173742761,\n",
       " 725813.850509377,\n",
       " 453959.24091305427,\n",
       " 299080.03620377055,\n",
       " 442960.3037415646,\n",
       " 656728.1536933121,\n",
       " 555618.616538624,\n",
       " 283792.4058305485,\n",
       " 298499.13756836404,\n",
       " 560022.0310328273,\n",
       " 407783.6054301582,\n",
       " 675369.257425705,\n",
       " 495112.459436695,\n",
       " 913622.2382183488,\n",
       " 380327.70459004655,\n",
       " 294728.4095847184,\n",
       " 390443.63967919035,\n",
       " 288093.25816219137,\n",
       " 359400.7460462926,\n",
       " 340333.1756096927,\n",
       " 398543.02430967067,\n",
       " 910401.1180011583,\n",
       " 580885.2680512484,\n",
       " 361267.0103958795,\n",
       " 504592.9785524764,\n",
       " 658743.6030359911,\n",
       " 256937.04584451034,\n",
       " 542592.4855578692,\n",
       " 359556.09809808474,\n",
       " 635032.8315319719,\n",
       " 628711.0232539003,\n",
       " 466736.2215000667,\n",
       " 288451.55475350545,\n",
       " 439129.2627519313,\n",
       " 347648.46270019613,\n",
       " 880108.252841753,\n",
       " 357423.35946391843,\n",
       " 564035.6810899847,\n",
       " 415600.69204266154,\n",
       " 387396.41193869326,\n",
       " 353160.686421624,\n",
       " 345540.82290702465,\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
