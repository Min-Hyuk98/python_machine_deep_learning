{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jang\\\\python_machine_deep_learning\\\\7. Ensemble learning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재경로 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\") \n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 집 고유아이디\\ndate: 집이 팔린 날짜 \\nprice: 집 가격 (타겟변수)\\nbedrooms: 주택 당 침실 개수\\nbathrooms: 주택 당 화장실 개수\\nfloors: 전체 층 개수\\nwaterfront: 해변이 보이는지 (0, 1)\\ncondition: 집 청소상태 (1~5)\\ngrade: King County grading system 으로 인한 평점 (1~13)\\nyr_built: 집이 지어진 년도\\nyr_renovated: 집이 리모델링 된 년도\\nzipcode: 우편번호\\nlat: 위도\\nlong: 경도\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: 집 고유아이디\n",
    "date: 집이 팔린 날짜 \n",
    "price: 집 가격 (타겟변수)\n",
    "bedrooms: 주택 당 침실 개수\n",
    "bathrooms: 주택 당 화장실 개수\n",
    "floors: 전체 층 개수\n",
    "waterfront: 해변이 보이는지 (0, 1)\n",
    "condition: 집 청소상태 (1~5)\n",
    "grade: King County grading system 으로 인한 평점 (1~13)\n",
    "yr_built: 집이 지어진 년도\n",
    "yr_renovated: 집이 리모델링 된 년도\n",
    "zipcode: 우편번호\n",
    "lat: 위도\n",
    "long: 경도\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 21613 nVar: 14\n"
     ]
    }
   ],
   "source": [
    "nCar = data.shape[0] # 데이터 개수\n",
    "nVar = data.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis = 1) # id, date, zipcode, lat, long  제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수를 이진형 변수로 변환\n",
    "- 범주형 변수는 waterfront 컬럼 뿐이며, 이진 분류이기 때문에 0, 1로 표현한다.\n",
    "- 데이터에서 0, 1로 표현되어 있으므로 과정 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price'])) # Price를 제외한 모든 행\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 7:3\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. regression model에 bagging 적용 안한것과 한것의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증 (Stats_Models 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2776.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 20 Sep 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:21:10</td>     <th>  Log-Likelihood:    </th> <td>-2.0826e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15129</td>      <th>  AIC:               </th>  <td>4.165e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15120</td>      <th>  BIC:               </th>  <td>4.166e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td> 7.186e+06</td> <td> 1.73e+05</td> <td>   41.548</td> <td> 0.000</td> <td> 6.85e+06</td> <td> 7.52e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>    <td> 1.303e+05</td> <td> 3960.833</td> <td>   32.889</td> <td> 0.000</td> <td> 1.23e+05</td> <td> 1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>     <td>-2224.7910</td> <td> 2382.356</td> <td>   -0.934</td> <td> 0.350</td> <td>-6894.497</td> <td> 2444.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition</th>    <td> 1.641e+04</td> <td> 3169.013</td> <td>    5.178</td> <td> 0.000</td> <td> 1.02e+04</td> <td> 2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>       <td> 1946.3052</td> <td> 4336.838</td> <td>    0.449</td> <td> 0.654</td> <td>-6554.422</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>        <td> 1.956e+05</td> <td> 2199.540</td> <td>   88.924</td> <td> 0.000</td> <td> 1.91e+05</td> <td>    2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>   <td> 7.555e+05</td> <td> 2.26e+04</td> <td>   33.479</td> <td> 0.000</td> <td> 7.11e+05</td> <td>    8e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>     <td>-4300.7865</td> <td>   88.073</td> <td>  -48.832</td> <td> 0.000</td> <td>-4473.420</td> <td>-4128.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th> <td>   12.7325</td> <td>    5.043</td> <td>    2.525</td> <td> 0.012</td> <td>    2.847</td> <td>   22.618</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13447.374</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1684794.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.763</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>54.147</td>   <th>  Cond. No.          </th>  <td>1.82e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.82e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.595\n",
       "Model:                            OLS   Adj. R-squared:                  0.595\n",
       "Method:                 Least Squares   F-statistic:                     2776.\n",
       "Date:                Sun, 20 Sep 2020   Prob (F-statistic):               0.00\n",
       "Time:                        20:21:10   Log-Likelihood:            -2.0826e+05\n",
       "No. Observations:               15129   AIC:                         4.165e+05\n",
       "Df Residuals:                   15120   BIC:                         4.166e+05\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const         7.186e+06   1.73e+05     41.548      0.000    6.85e+06    7.52e+06\n",
       "bathrooms     1.303e+05   3960.833     32.889      0.000    1.23e+05    1.38e+05\n",
       "bedrooms     -2224.7910   2382.356     -0.934      0.350   -6894.497    2444.915\n",
       "condition     1.641e+04   3169.013      5.178      0.000    1.02e+04    2.26e+04\n",
       "floors        1946.3052   4336.838      0.449      0.654   -6554.422    1.04e+04\n",
       "grade         1.956e+05   2199.540     88.924      0.000    1.91e+05       2e+05\n",
       "waterfront    7.555e+05   2.26e+04     33.479      0.000    7.11e+05       8e+05\n",
       "yr_built     -4300.7865     88.073    -48.832      0.000   -4473.420   -4128.153\n",
       "yr_renovated    12.7325      5.043      2.525      0.012       2.847      22.618\n",
       "==============================================================================\n",
       "Omnibus:                    13447.374   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1684794.827\n",
       "Skew:                           3.763   Prob(JB):                         0.00\n",
       "Kurtosis:                      54.147   Cond. No.                     1.82e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.82e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sm_train_x = sm.add_constant(train_x, has_constant=\"add\")\n",
    "sm_model = sm.OLS(train_y, sm_train_x)\n",
    "fitted_sm_model = sm_model.fit()\n",
    "fitted_sm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239804.29670858168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_test_x = sm.add_constant(test_x, has_constant=\"add\")\n",
    "sm_model_predict = fitted_sm_model.predict(sm_test_x)\n",
    "\n",
    "sqrt(mean_squared_error(sm_model_predict, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 선형 회귀 모형에 적합 후 평가 (for문 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x의 데이터 수: 15129\n",
      "복원추출했을 때 unique한 데이터 수:  9534\n",
      "MSE:  241385.18961266533\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9613\n",
      "MSE:  239707.23080231572\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9607\n",
      "MSE:  239902.8780735903\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9530\n",
      "MSE:  239542.55608655547\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9525\n",
      "MSE:  239669.15250576814\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9587\n",
      "MSE:  240113.79244983726\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9538\n",
      "MSE:  240265.65376426486\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9639\n",
      "MSE:  239668.67652540538\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9525\n",
      "MSE:  239754.82088075008\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9596\n",
      "MSE:  239694.8995337847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_predict_result = []\n",
    "print(\"train_x의 데이터 수:\", train_x.shape[0])\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) ## train_x의 인덱스중에서 train_x의 데이터수만큼 복원추출로 뽑는다\n",
    "    print(\"복원추출했을 때 unique한 데이터 수: \", len(set(random_data_index))) ## set을 통해 unique한 데이터인덱스만 고를 수 있다\n",
    "    \n",
    "    sm_train_x = train_x.iloc[random_data_index]\n",
    "    sm_train_x = sm.add_constant(sm_train_x, has_constant=\"add\")\n",
    "    sm_train_y = train_y.iloc[random_data_index]\n",
    "    \n",
    "    sm_model = sm.OLS(sm_train_y, sm_train_x)\n",
    "    fitted_sm_model = sm_model.fit()\n",
    "    \n",
    "    pred = fitted_sm_model.predict(sm_test_x)\n",
    "    bagging_predict_result.append(pred)\n",
    "    \n",
    "    print(\"MSE: \", sqrt(mean_squared_error(pred, test_y)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ensemble 결과 mse값:', 239688.51285492248)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict = [] ## \n",
    "\n",
    "for list2_index in range(test_x.shape[0]):  # 0 ~ 15128\n",
    "    temp_predict = []\n",
    "    for list_index in range(len(bagging_predict_result)):  # 0 ~ 9\n",
    "        temp_predict.append(bagging_predict_result[list_index].values[list2_index])\n",
    "    bagging_predict.append(np.mean(temp_predict))\n",
    "    \n",
    "\"Ensemble 결과 mse값:\", sqrt( mean_squared_error(bagging_predict, test_y))\n",
    "\n",
    "\n",
    "# 지금 상황에서는, 오히려 일반 모델보다 앙상블 모델의 성능이 더 안좋아졌다\n",
    "# 앙상블기법은 overfitting이 잘되는 모델들을 결합해야 성능이 좋은데,\n",
    "# 이 데이터를 선형회귀모델로 만들때 overfitting이 별로 없는것으로 추정된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증 (Scikit-Learn 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239804.29670858147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "regression_model = LinearRegression() # 선형 회귀 모형\n",
    "linear_model1 = regression_model.fit(train_x, train_y) # 학습 데이터를 선형 회귀 모형에 적합\n",
    "\n",
    "predict1 = linear_model1.predict(test_x) # 학습된 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict1, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 선형 회귀 모형에 적합 후 평가 (Sampling 10번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239753.82767766988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging_model = BaggingRegressor(base_estimator = regression_model, # 선형회귀모형\n",
    "                                 n_estimators = 5, # 5번 샘플링  --> 위의 for문 사용시의 for _ in range(10):의 10과 같은 역할\n",
    "                                 verbose = 1) # 학습 과정 표시\n",
    "linear_model2 = bagging_model.fit(train_x, train_y) # 학습 진행\n",
    "predict2 = linear_model2.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 선형 회귀 모형에 적합 후 평가 (Sampling 30번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239885.781970098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_model2 = BaggingRegressor(base_estimator = regression_model, # 선형 회귀모형\n",
    "                                  n_estimators = 30, # 30번 샘플링\n",
    "                                  verbose = 1) # 학습 과정 표시\n",
    "linear_model3 = bagging_model2.fit(train_x, train_y) # 학습 진행\n",
    "predict3 = linear_model3.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict3, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 의사결정나무모형에 bagging 적용 안한것과 한것 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 의사결정나무모형에 적합 후 평가 데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 299002.7920847322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_tree_model = DecisionTreeRegressor() # 의사결정나무 모형\n",
    "tree_model1 = decision_tree_model.fit(train_x, train_y) # 학습 데이터를 의사결정나무 모형에 적합\n",
    "predict1 = tree_model1.predict(test_x) # 학습된 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict1, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 의사결정나무모형에 적합 후 평가 (for문 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x의 데이터 수: 15129\n",
      "복원추출했을 때 unique한 데이터 수:  9573\n",
      "MSE:  289199.6294340458\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9552\n",
      "MSE:  292446.76936214796\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9644\n",
      "MSE:  287372.5762739883\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9592\n",
      "MSE:  282803.83367055195\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9647\n",
      "MSE:  271422.89246585825\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9522\n",
      "MSE:  306337.32836935256\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9606\n",
      "MSE:  295887.0246649136\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9569\n",
      "MSE:  292410.49493883085\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9453\n",
      "MSE:  282776.76356550626\n",
      "\n",
      "복원추출했을 때 unique한 데이터 수:  9548\n",
      "MSE:  302838.71288132475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_predict_result = []\n",
    "print(\"train_x의 데이터 수:\", train_x.shape[0])\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) ## train_x의 인덱스중에서 train_x의 데이터수만큼 복원추출로 뽑는다\n",
    "    print(\"복원추출했을 때 unique한 데이터 수: \", len(set(random_data_index))) ## set을 통해 unique한 데이터인덱스만 고를 수 있다\n",
    "    \n",
    "    sm_train_x = train_x.iloc[random_data_index]\n",
    "    sm_train_y = train_y.iloc[random_data_index]\n",
    "    \n",
    "    decision_tree_model = DecisionTreeRegressor()\n",
    "    tree_model = decision_tree_model.fit(sm_train_x, sm_train_y)\n",
    "    predict_tree = tree_model.predict(test_x)\n",
    "    bagging_predict_result.append(predict_tree)\n",
    "    \n",
    "    print(\"MSE: \", sqrt(mean_squared_error(predict_tree, test_y)))\n",
    "    print()\n",
    "    \n",
    "    ## 각각으로 보면 overfitting때문에 linear regression보다 오히려 성능 안좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ensemble 결과 mse값:', 238027.50878520074)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict = [] ## \n",
    "\n",
    "for list2_index in range(test_x.shape[0]):  # 0 ~ 15128\n",
    "    temp_predict = []\n",
    "    for list_index in range(len(bagging_predict_result)):  # 0 ~ 9\n",
    "        temp_predict.append(bagging_predict_result[list_index][list2_index])\n",
    "    bagging_predict.append(np.mean(temp_predict))\n",
    "    \n",
    "\"Ensemble 결과 mse값:\", sqrt( mean_squared_error(bagging_predict, test_y))\n",
    "\n",
    "\n",
    "## 위의 10개를 평균내어 진짜 성능을 구하니, 훨씬 좋아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 의사결정나무모형에 적합 후 평가 (Sampling 10번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 237828.27321561766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_decision_tree_model1 = BaggingRegressor(base_estimator = decision_tree_model, # 의사결정나무 모형\n",
    "                                                n_estimators = 5, # 5번 샘플링\n",
    "                                                verbose = 1) # 학습 과정 표시\n",
    "tree_model2 = bagging_decision_tree_model1.fit(train_x, train_y) # 학습 진행\n",
    "predict2 = tree_model2.predict(test_x) # 학습된 Bagging 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 의사결정나무모형에 적합 후 평가 (Sampling 30번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 235220.39325524535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_decision_tree_model2 = BaggingRegressor(base_estimator = decision_tree_model, # 의사결정나무 모형\n",
    "                                                n_estimators = 30, # 30번 샘플링\n",
    "                                                verbose = 1) # 학습 과정 표시\n",
    "tree_model3 = bagging_decision_tree_model2.fit(train_x, train_y) # 학습 진행\n",
    "predict3 = tree_model3.predict(test_x) # 학습된 Bagging 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict3, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators를 100, 200 처럼 많이 높인다고 무조건 좋은것은 아니다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
