{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 학습 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구조 정의\n",
    "- keras 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- padding='same' ~> zero padding 적용 ~> 크기 유지\n",
    "- padding='valid' ~> zero padding 적용안함 ~> 크기 감소\n",
    "- Conv2D( channel수, (filter크기), padding여부, activation_func )\n",
    "- MaxPool2D() ~> default로 2x2filter 사용 ~> 크기 반으로 줄여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():nv2D(32, (3, 3), padding='same', activation='relu'), # 28 x 28 x 32\n",
    "                        MaxPool2D(), # 14 x 14 x 28\n",
    "                       Conv2D(64, (3, 3), padding='same', activation='relu'), # 14 x 14 x 64\n",
    "                        MaxPool2D(), # 7 x 7 x 64\n",
    "                       Conv2D(128, (3, 3), pad\n",
    "    return Sequential([Coding='same', activation='relu'), # 7 x 7 x 128\n",
    "                       Flatten(), # 6272\n",
    "                       Dense(128, activation='relu'), # 128\n",
    "                       Dense(10, activation='softmax') # 10\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) ## (batch크기, height, width)\n",
    "print(x_train[0].shape)  ## (height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN을 위해 N(batch), H(height), W(width), C (channel) 로 rank=4인 데이터셋이 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 136s 73ms/step - loss: 0.2005 - accuracy: 0.9251 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 158s 84ms/step - loss: 0.1678 - accuracy: 0.9380 - val_loss: 0.2378 - val_accuracy: 0.9171\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 146s 78ms/step - loss: 0.1422 - accuracy: 0.9463 - val_loss: 0.2425 - val_accuracy: 0.9213\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 158s 84ms/step - loss: 0.1161 - accuracy: 0.9561 - val_loss: 0.2502 - val_accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 156s 83ms/step - loss: 0.0950 - accuracy: 0.9638 - val_loss: 0.2671 - val_accuracy: 0.9181\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 151s 80ms/step - loss: 0.0762 - accuracy: 0.9710 - val_loss: 0.3033 - val_accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 150s 80ms/step - loss: 0.0654 - accuracy: 0.9754 - val_loss: 0.3377 - val_accuracy: 0.9190\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 154s 82ms/step - loss: 0.0519 - accuracy: 0.9803 - val_loss: 0.3579 - val_accuracy: 0.9164\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 159s 85ms/step - loss: 0.0484 - accuracy: 0.9816 - val_loss: 0.3928 - val_accuracy: 0.9195\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 160s 85ms/step - loss: 0.0413 - accuracy: 0.9844 - val_loss: 0.4431 - val_accuracy: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22fe144fb70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
