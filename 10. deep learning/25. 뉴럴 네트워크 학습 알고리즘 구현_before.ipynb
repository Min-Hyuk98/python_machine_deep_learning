{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴럴 네트워크 학습 알고리즘 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "\n",
    "- 보통은 Keras로 하지만, 지금은 학습목적으로 tensorflow방식 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구조 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()  ## 상속자인 tf.keras.Model 클래스의 __init__ 해주기\n",
    "        self.flatten = tf.keras.layers.Flatten(input_shape=(28,28))  ## 28 X 28행렬데이터를 벡터형태로 flatten\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation='relu') ## 첫번째 layer에는 32개의 뉴런 사용\n",
    "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense5 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x, trainig=None, mask=None):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        return self.dense5(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 함수 구현\n",
    "\n",
    "- image : 입력값\n",
    "- labels : 출력값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, image, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape: ## 이 안에서 하는 연산은 모두 미분을 계산해놓음  -> 나중에 편리하게 뽑아쓸 수 있음\n",
    "        predictions = model(image) # batch_size=32. label종류=10가지 일때 --> (32 X 10) 의 형태로 나올 것.\n",
    "        loss = loss_object(labels, predictions) \n",
    "    gradients = tape.gradient(loss, model.trainable_variables) # loss를 모든 trainable_variables로 미분\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # zip()  ->  gradients와 trainable_variables를 같이 iteration 할 수 있는 iteration 객체\n",
    "        \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(model, image, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(image) # batch_size=32. label종류=10가지 일때 --> (32 X 10) 의 형태로 나올 것.\n",
    "    loss = loss_object(labels, predictions) \n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1024).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 및 최적화 알고리즘 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8] (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train, y_train.shape) ## y의 범주들이 one-hot encoding되어있지 않고 각각이 범주이름을 나타낸다 --> SparseCategoricalCrossentropy 사용\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 루프 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss: 0.024603623896837234, Accuracy: 99.20160675048828, Test Loss: 0.11980361491441727, Test Accuracy: 97.43000030517578\n",
      "Epoch 2: loss: 0.019587818533182144, Accuracy: 99.3550033569336, Test Loss: 0.10614775121212006, Test Accuracy: 97.97999572753906\n",
      "Epoch 3: loss: 0.021768029779195786, Accuracy: 99.29833221435547, Test Loss: 0.10762132704257965, Test Accuracy: 97.64999389648438\n",
      "Epoch 4: loss: 0.01919660158455372, Accuracy: 99.37166595458984, Test Loss: 0.1312568634748459, Test Accuracy: 97.58999633789062\n",
      "Epoch 5: loss: 0.01940007507801056, Accuracy: 99.39167022705078, Test Loss: 0.14052623510360718, Test Accuracy: 97.1500015258789\n",
      "Epoch 6: loss: 0.017693521454930305, Accuracy: 99.41166687011719, Test Loss: 0.12548251450061798, Test Accuracy: 97.87999725341797\n",
      "Epoch 7: loss: 0.016143256798386574, Accuracy: 99.50167083740234, Test Loss: 0.11711866408586502, Test Accuracy: 97.8499984741211\n",
      "Epoch 8: loss: 0.016697455197572708, Accuracy: 99.45832824707031, Test Loss: 0.13748590648174286, Test Accuracy: 97.63999938964844\n",
      "Epoch 9: loss: 0.015689658001065254, Accuracy: 99.47999572753906, Test Loss: 0.1466943472623825, Test Accuracy: 97.5\n",
      "Epoch 10: loss: 0.015326505526900291, Accuracy: 99.54666137695312, Test Loss: 0.13294118642807007, Test Accuracy: 97.93000030517578\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for image, labels in train_ds:\n",
    "        train_step(model, image, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "        \n",
    "    for image, labels in test_ds:\n",
    "        test_step(model, image, labels, loss_object, test_loss, test_accuracy)\n",
    "    \n",
    "    print('Epoch {}: loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'.format(epoch+1, \n",
    "                                                                                       train_loss.result(), \n",
    "                                                                                       train_accuracy.result() * 100, \n",
    "                                                                                       test_loss.result(), \n",
    "                                                                                       test_accuracy.result() * 100))\n",
    "    \n",
    "    ## 누적되는것을 방지하기 위해 reset해줌\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
